{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3 import DDPG\n",
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "from stable_baselines3 import TD3\n",
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"MountainCar-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_147665/3660357104.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# The noise objects for DDPG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mn_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0maction_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNormalActionNoise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDDPG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MlpPolicy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_noise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maction_noise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# The noise objects for DDPG\n",
    "n_actions = env.action_space.shape[-1]\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "\n",
    "model = DDPG(\"MlpPolicy\", env, action_noise=action_noise, verbose=1)\n",
    "model.learn(total_timesteps=10000, log_interval=10)\n",
    "model.save(\"ddpg_MountainCar\")\n",
    "env = model.get_env()\n",
    "\n",
    "del model # remove to demonstrate saving and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.49e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 10        |\n",
      "|    fps             | 153       |\n",
      "|    time_elapsed    | 13        |\n",
      "|    total timesteps | 2000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 31.5      |\n",
      "|    critic_loss     | 0.0825    |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 1800      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.32e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 20        |\n",
      "|    fps             | 149       |\n",
      "|    time_elapsed    | 26        |\n",
      "|    total timesteps | 4000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 57.9      |\n",
      "|    critic_loss     | 0.374     |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 3800      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -978     |\n",
      "| time/              |          |\n",
      "|    episodes        | 30       |\n",
      "|    fps             | 147      |\n",
      "|    time_elapsed    | 40       |\n",
      "|    total timesteps | 6000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 62.6     |\n",
      "|    critic_loss     | 0.488    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 5800     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -766     |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 149      |\n",
      "|    time_elapsed    | 53       |\n",
      "|    total timesteps | 8000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 61       |\n",
      "|    critic_loss     | 0.827    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 7800     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -642     |\n",
      "| time/              |          |\n",
      "|    episodes        | 50       |\n",
      "|    fps             | 150      |\n",
      "|    time_elapsed    | 66       |\n",
      "|    total timesteps | 10000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 58.2     |\n",
      "|    critic_loss     | 1.06     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 9800     |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "# The noise objects for TD3\n",
    "n_actions = env.action_space.shape[-1]\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "\n",
    "model = TD3(\"MlpPolicy\", env, action_noise=action_noise, verbose=1)\n",
    "model.learn(total_timesteps=10000, log_interval=10)\n",
    "model.save(\"td3_pendulum\")\n",
    "env = model.get_env()\n",
    "\n",
    "del model # remove to demonstrate saving and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Creating environment from the given name 'Pendulum-v0'\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -1.5e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total timesteps | 800      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 24.7     |\n",
      "|    critic_loss     | 0.258    |\n",
      "|    ent_coef        | 0.813    |\n",
      "|    ent_coef_loss   | -0.336   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 699      |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.47e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 84        |\n",
      "|    time_elapsed    | 19        |\n",
      "|    total timesteps | 1600      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 48.2      |\n",
      "|    critic_loss     | 0.145     |\n",
      "|    ent_coef        | 0.646     |\n",
      "|    ent_coef_loss   | -0.635    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 1499      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.37e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 81        |\n",
      "|    time_elapsed    | 29        |\n",
      "|    total timesteps | 2400      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 70.9      |\n",
      "|    critic_loss     | 0.167     |\n",
      "|    ent_coef        | 0.53      |\n",
      "|    ent_coef_loss   | -0.554    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 2299      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.27e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 80        |\n",
      "|    time_elapsed    | 39        |\n",
      "|    total timesteps | 3200      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 84.2      |\n",
      "|    critic_loss     | 0.558     |\n",
      "|    ent_coef        | 0.451     |\n",
      "|    ent_coef_loss   | -0.547    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 3099      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.15e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 20        |\n",
      "|    fps             | 79        |\n",
      "|    time_elapsed    | 50        |\n",
      "|    total timesteps | 4000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 90.6      |\n",
      "|    critic_loss     | 0.937     |\n",
      "|    ent_coef        | 0.391     |\n",
      "|    ent_coef_loss   | -0.407    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 3899      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -991     |\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 79       |\n",
      "|    time_elapsed    | 60       |\n",
      "|    total timesteps | 4800     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 88.9     |\n",
      "|    critic_loss     | 1.33     |\n",
      "|    ent_coef        | 0.336    |\n",
      "|    ent_coef_loss   | -0.286   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 4699     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.sac.sac.SAC at 0x7f9192935940>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Custom actor architecture with two layers of 64 units each\n",
    "# Custom critic architecture with two layers of 400 and 300 units\n",
    "policy_kwargs = dict(net_arch=dict(pi=[64, 64], qf=[400, 300]))\n",
    "# Create the agent\n",
    "model = SAC(\"MlpPolicy\", \"Pendulum-v0\", policy_kwargs=policy_kwargs, verbose=1)\n",
    "model.learn(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-124.95492]\n",
      "[-1.7905357]\n",
      "[-1.904977]\n",
      "[-238.75716]\n",
      "[-238.7521]\n"
     ]
    }
   ],
   "source": [
    "model = TD3.load(\"td3_pendulum\")\n",
    "\n",
    "obs = env.reset()\n",
    "for i in range(5):\n",
    "    obs = env.reset()\n",
    "    tt_reward = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        action, _states = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        env.render()\n",
    "        tt_reward += reward\n",
    "    print(tt_reward)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ReinforcementLearning",
   "language": "python",
   "name": "reinforcementlearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
