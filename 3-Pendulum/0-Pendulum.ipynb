{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3 import DDPG\n",
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "from stable_baselines3 import TD3\n",
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"Pendulum-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.39e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 89        |\n",
      "|    time_elapsed    | 8         |\n",
      "|    total timesteps | 800       |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 23        |\n",
      "|    critic_loss     | 0.289     |\n",
      "|    ent_coef        | 0.813     |\n",
      "|    ent_coef_loss   | -0.334    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 699       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.46e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 85        |\n",
      "|    time_elapsed    | 18        |\n",
      "|    total timesteps | 1600      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 48.6      |\n",
      "|    critic_loss     | 0.162     |\n",
      "|    ent_coef        | 0.648     |\n",
      "|    ent_coef_loss   | -0.62     |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 1499      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.38e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 85        |\n",
      "|    time_elapsed    | 28        |\n",
      "|    total timesteps | 2400      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 69.3      |\n",
      "|    critic_loss     | 0.388     |\n",
      "|    ent_coef        | 0.529     |\n",
      "|    ent_coef_loss   | -0.573    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 2299      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.18e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 85        |\n",
      "|    time_elapsed    | 37        |\n",
      "|    total timesteps | 3200      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 78.9      |\n",
      "|    critic_loss     | 0.569     |\n",
      "|    ent_coef        | 0.449     |\n",
      "|    ent_coef_loss   | -0.607    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 3099      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -995     |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 46       |\n",
      "|    total timesteps | 4000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 78.9     |\n",
      "|    critic_loss     | 0.813    |\n",
      "|    ent_coef        | 0.385    |\n",
      "|    ent_coef_loss   | -0.633   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 3899     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -880     |\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 56       |\n",
      "|    total timesteps | 4800     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 79       |\n",
      "|    critic_loss     | 1.62     |\n",
      "|    ent_coef        | 0.323    |\n",
      "|    ent_coef_loss   | -0.388   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 4699     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -771     |\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 65       |\n",
      "|    total timesteps | 5600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 79.6     |\n",
      "|    critic_loss     | 1.29     |\n",
      "|    ent_coef        | 0.267    |\n",
      "|    ent_coef_loss   | -0.727   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 5499     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -686     |\n",
      "| time/              |          |\n",
      "|    episodes        | 32       |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 74       |\n",
      "|    total timesteps | 6400     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 70.6     |\n",
      "|    critic_loss     | 2.39     |\n",
      "|    ent_coef        | 0.223    |\n",
      "|    ent_coef_loss   | -0.449   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 6299     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -627     |\n",
      "| time/              |          |\n",
      "|    episodes        | 36       |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 84       |\n",
      "|    total timesteps | 7200     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 74.3     |\n",
      "|    critic_loss     | 1.45     |\n",
      "|    ent_coef        | 0.188    |\n",
      "|    ent_coef_loss   | -0.246   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 7099     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -579     |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 94       |\n",
      "|    total timesteps | 8000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 61.8     |\n",
      "|    critic_loss     | 1.48     |\n",
      "|    ent_coef        | 0.159    |\n",
      "|    ent_coef_loss   | -0.544   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 7899     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -532     |\n",
      "| time/              |          |\n",
      "|    episodes        | 44       |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 103      |\n",
      "|    total timesteps | 8800     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 62.4     |\n",
      "|    critic_loss     | 1.57     |\n",
      "|    ent_coef        | 0.135    |\n",
      "|    ent_coef_loss   | -0.494   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 8699     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -493     |\n",
      "| time/              |          |\n",
      "|    episodes        | 48       |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total timesteps | 9600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 48.9     |\n",
      "|    critic_loss     | 2.22     |\n",
      "|    ent_coef        | 0.112    |\n",
      "|    ent_coef_loss   | -1.05    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 9499     |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = SAC(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=10000, log_interval=4)\n",
    "model.save(\"sac_pendulum\")\n",
    "del model # remove to demonstrate saving and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.38e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 10        |\n",
      "|    fps             | 156       |\n",
      "|    time_elapsed    | 12        |\n",
      "|    total timesteps | 2000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 55.4      |\n",
      "|    critic_loss     | 0.077     |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 1800      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -1.1e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 150      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total timesteps | 4000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 84.8     |\n",
      "|    critic_loss     | 0.654    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 3800     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -789     |\n",
      "| time/              |          |\n",
      "|    episodes        | 30       |\n",
      "|    fps             | 152      |\n",
      "|    time_elapsed    | 39       |\n",
      "|    total timesteps | 6000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 75       |\n",
      "|    critic_loss     | 0.868    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 5800     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -623     |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 153      |\n",
      "|    time_elapsed    | 51       |\n",
      "|    total timesteps | 8000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 63.8     |\n",
      "|    critic_loss     | 0.952    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 7800     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -534     |\n",
      "| time/              |          |\n",
      "|    episodes        | 50       |\n",
      "|    fps             | 155      |\n",
      "|    time_elapsed    | 64       |\n",
      "|    total timesteps | 10000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 55.2     |\n",
      "|    critic_loss     | 1.48     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 9800     |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "# The noise objects for DDPG\n",
    "n_actions = env.action_space.shape[-1]\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "\n",
    "model = DDPG(\"MlpPolicy\", env, action_noise=action_noise, verbose=1)\n",
    "model.learn(total_timesteps=10000, log_interval=10)\n",
    "model.save(\"ddpg_pendulum\")\n",
    "env = model.get_env()\n",
    "\n",
    "del model # remove to demonstrate saving and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.49e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 10        |\n",
      "|    fps             | 153       |\n",
      "|    time_elapsed    | 13        |\n",
      "|    total timesteps | 2000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 31.5      |\n",
      "|    critic_loss     | 0.0825    |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 1800      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.32e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 20        |\n",
      "|    fps             | 149       |\n",
      "|    time_elapsed    | 26        |\n",
      "|    total timesteps | 4000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 57.9      |\n",
      "|    critic_loss     | 0.374     |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 3800      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -978     |\n",
      "| time/              |          |\n",
      "|    episodes        | 30       |\n",
      "|    fps             | 147      |\n",
      "|    time_elapsed    | 40       |\n",
      "|    total timesteps | 6000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 62.6     |\n",
      "|    critic_loss     | 0.488    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 5800     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -766     |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 149      |\n",
      "|    time_elapsed    | 53       |\n",
      "|    total timesteps | 8000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 61       |\n",
      "|    critic_loss     | 0.827    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 7800     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -642     |\n",
      "| time/              |          |\n",
      "|    episodes        | 50       |\n",
      "|    fps             | 150      |\n",
      "|    time_elapsed    | 66       |\n",
      "|    total timesteps | 10000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 58.2     |\n",
      "|    critic_loss     | 1.06     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 9800     |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "# The noise objects for TD3\n",
    "n_actions = env.action_space.shape[-1]\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "\n",
    "model = TD3(\"MlpPolicy\", env, action_noise=action_noise, verbose=1)\n",
    "model.learn(total_timesteps=10000, log_interval=10)\n",
    "model.save(\"td3_pendulum\")\n",
    "env = model.get_env()\n",
    "\n",
    "del model # remove to demonstrate saving and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Creating environment from the given name 'Pendulum-v0'\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -1.5e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total timesteps | 800      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 24.7     |\n",
      "|    critic_loss     | 0.258    |\n",
      "|    ent_coef        | 0.813    |\n",
      "|    ent_coef_loss   | -0.336   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 699      |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.47e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 84        |\n",
      "|    time_elapsed    | 19        |\n",
      "|    total timesteps | 1600      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 48.2      |\n",
      "|    critic_loss     | 0.145     |\n",
      "|    ent_coef        | 0.646     |\n",
      "|    ent_coef_loss   | -0.635    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 1499      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.37e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 81        |\n",
      "|    time_elapsed    | 29        |\n",
      "|    total timesteps | 2400      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 70.9      |\n",
      "|    critic_loss     | 0.167     |\n",
      "|    ent_coef        | 0.53      |\n",
      "|    ent_coef_loss   | -0.554    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 2299      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.27e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 80        |\n",
      "|    time_elapsed    | 39        |\n",
      "|    total timesteps | 3200      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 84.2      |\n",
      "|    critic_loss     | 0.558     |\n",
      "|    ent_coef        | 0.451     |\n",
      "|    ent_coef_loss   | -0.547    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 3099      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.15e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 20        |\n",
      "|    fps             | 79        |\n",
      "|    time_elapsed    | 50        |\n",
      "|    total timesteps | 4000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 90.6      |\n",
      "|    critic_loss     | 0.937     |\n",
      "|    ent_coef        | 0.391     |\n",
      "|    ent_coef_loss   | -0.407    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 3899      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -991     |\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 79       |\n",
      "|    time_elapsed    | 60       |\n",
      "|    total timesteps | 4800     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 88.9     |\n",
      "|    critic_loss     | 1.33     |\n",
      "|    ent_coef        | 0.336    |\n",
      "|    ent_coef_loss   | -0.286   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 4699     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.sac.sac.SAC at 0x7f9192935940>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Custom actor architecture with two layers of 64 units each\n",
    "# Custom critic architecture with two layers of 400 and 300 units\n",
    "policy_kwargs = dict(net_arch=dict(pi=[64, 64], qf=[400, 300]))\n",
    "# Create the agent\n",
    "model = SAC(\"MlpPolicy\", \"Pendulum-v0\", policy_kwargs=policy_kwargs, verbose=1)\n",
    "model.learn(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-333.6367]\n",
      "[-113.9706]\n",
      "[-116.76126]\n",
      "[-117.73746]\n",
      "[-114.0326]\n"
     ]
    }
   ],
   "source": [
    "model = SAC.load(\"sac_pendulum\")\n",
    "\n",
    "obs = env.reset()\n",
    "for i in range(5):\n",
    "    obs = env.reset()\n",
    "    tt_reward = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        action, _states = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        env.render()\n",
    "        tt_reward += reward\n",
    "    print(tt_reward)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(-2.0, 2.0, (1,), float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(-8.0, 8.0, (3,), float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ReinforcementLearning",
   "language": "python",
   "name": "reinforcementlearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
